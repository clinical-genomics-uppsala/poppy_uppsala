__author__ = "Arielle R. Munters"
__copyright__ = "Copyright 2024, Arielle R. Munters"
__email__ = "arielle.munters@scilifelab.uu.se"
__license__ = "GPL-3"


ruleorder: filtering_bcftools_filter_include_region > snv_indels_bgzip


# Include pipeline specific rules
include: "rules/common.smk"
include: "rules/version.smk"
include: "rules/bamsnap.smk"
include: "rules/results_report.smk"
include: "rules/sample_order_multiqc.smk"


# enforces version update first
ruleorder: version_update_poppy > bamsnap_create_pos_list


# 'All' rule, must be specified before any other modules are
# included, since they also contain 'All' rule
rule all:
    input:
        compile_output_file_list,


# Include modules
module poppy:
    snakefile:
        get_module_snakefile(
            config,
            "genomic-medicine-sweden/poppy",
            path="workflow/Snakefile",
            tag=config["poppy_version"],
        )
    config:
        config


use rule * from poppy exclude all, copy_bamsnap


module alignment:
    snakefile:
        get_module_snakefile(
            config,
            "hydra-genetics/alignment",
            path="workflow/Snakefile",
            tag=config["modules"]["alignment"],
        )
    config:
        config


# use rule * from alignment as alignment_*


module annotation:
    snakefile:
        get_module_snakefile(
            config,
            "hydra-genetics/annotation",
            path="workflow/Snakefile",
            tag=config["modules"]["annotation"],
        )
    config:
        config


# use rule * from annotation as annotation_*


module cnv_sv:
    snakefile:
        get_module_snakefile(
            config,"hydra-genetics/cnv_sv", path="workflow/Snakefile", tag=config["modules"]["cnv_sv"],)
    config:
        config


# use rule * from cnv_sv as cnv_sv_*


use rule cnvkit_call from cnv_sv as cnv_sv_cnvkit_call with:
    input:
        segment="cnv_sv/cnvkit_batch/{sample}/{sample}_{type}.cns",
        vcf="snv_indels/bcbio_variation_recall_ensemble/{sample}_{type}.ensembled.vep_annotated.filter.germline.vcf.gz",
        purity=cnv_sv.get_tc_file,


use rule pindel_generate_config from cnv_sv as cnv_sv_pindel_generate_config with:
    input:
        bam="alignment/samtools_merge_bam/{sample}_{type}.bam",
        metrics="qc/picard_collect_insert_size_metrics/{sample}_{type}.insert_size_metrics.txt",


module filtering:
    snakefile:
        get_module_snakefile(
            config,
            "hydra-genetics/filtering",
            path="workflow/Snakefile",
            tag=config["modules"]["filtering"],
        )
    config:
        config


# use rule * from filtering as filtering_*


module prealignment:
    snakefile:
        get_module_snakefile(
            config,
            "hydra-genetics/prealignment",
            path="workflow/Snakefile",
            tag=config["modules"]["prealignment"],
        )
    config:
        config


# use rule * from prealignment as prealignment_*


module reports:
    snakefile:
        get_module_snakefile(
            config,
            "hydra-genetics/reports",
            path="workflow/Snakefile",
            tag=config["modules"]["reports"],
        )
    config:
        config


# use rule * from reports as reports_*


use rule * from poppy exclude all, copy_bamsnap


module snv_indels:
    snakefile:
        get_module_snakefile(
            config,
            "hydra-genetics/snv_indels",
            path="workflow/Snakefile",
            tag=config["modules"]["snv_indels"],
        )
    config:
        config


# use rule vt_normalize from snv_indels as snv_indels_vt_normalize_pindel with:
#     input:
#         vcf="cnv_sv/pindel_vcf/{sample}_{type}.no_tc.fix_af.vcf.gz",
#         tbi="cnv_sv/pindel_vcf/{sample}_{type}.no_tc.fix_af.vcf.gz.tbi",
#         ref=config["reference"]["fasta"],
#     output:
#         vcf=temp("cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.vcf.gz"),
#     log:
#         "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.vcf.gz.log",
#     benchmark:
#         repeat(
#             "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.vcf.gz.benchmark.tsv",
#             config.get("vt_normalize", {}).get("benchmark_repeats", 1),
#         )


use rule merge_af_complex_variants from snv_indels as snv_indels_merge_af_complex_variants_unsorted with:
    input:
        vcf="snv_indels/{caller}/{sample}_{type}.normalized.vcf.gz",
    output:
        vcf=temp("snv_indels/{caller}/{sample}_{type}.normalized.merged_af.unsorted.vcf.gz"),
    params:
        merge_method=config.get("merge_af_complex_variants", {}).get("merge_method", "skip"),
    log:
        "snv_indels/{caller}/{sample}_{type}.normalized.merged_af.vcf.gz.log",
    benchmark:
        repeat(
            "snv_indels/{caller}/{sample}_{type}.normalized.merged_af.vcf.gz.benchmark.tsv",
            config.get("merge_af_complex_variants", {}).get("benchmark_repeats", 1),
        )


use rule bcftools_sort from snv_indels as snv_indels_bcftools_sort_merged_af with:
    input:
        vcf="snv_indels/{caller}/{sample}_{type}.normalized.merged_af.unsorted.vcf.gz",
    output:
        vcf=temp("snv_indels/{caller}/{sample}_{type}.normalized.merged_af.sorted.vcf.gz"),
    log:
        "snv_indels/{caller}/{sample}_{type}.normalized.merged_af.sorted.vcf.gz.log",
    benchmark:
        repeat(
            "snv_indels/{caller}/{sample}_{type}.normalized.merged_af.sorted.vcf.gz.benchmark.tsv",
            config.get("bcftools_sort", {}).get("benchmark_repeats", 1),
        )


use rule merge_af_complex_variants from snv_indels as snv_indels_merge_af_complex_variants_pindel with:
    input:
        vcf="cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.vcf.gz",
        tabix="cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.vcf.gz.tbi",
    output:
        vcf=temp("cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.unsorted.vcf.gz"),
    params:
        merge_method=config.get("merge_af_complex_variants", {}).get("merge_method", "skip"),
    log:
        "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.vcf.gz.log",
    benchmark:
        repeat(
            "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.vcf.gz.benchmark.tsv",
            config.get("merge_af_complex_variants", {}).get("benchmark_repeats", 1),
        )


use rule bcftools_sort from snv_indels as snv_indels_bcftools_sort_merged_af_pindel with:
    input:
        vcf="cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.unsorted.vcf.gz",
    output:
        vcf=temp("cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.sorted.vcf.gz"),
    log:
        "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.sorted.vcf.gz.log",
    benchmark:
        repeat(
            "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.sorted.vcf.gz.benchmark.tsv",
            config.get("bcftools_sort", {}).get("benchmark_repeats", 1),
        )


use rule bcbio_variation_recall_ensemble from snv_indels as snv_indels_bcbio_variation_recall_ensemble with:
    input:
        vcfs=expand(
            "snv_indels/{caller}/{{sample}}_{{type}}.normalized.merged_af.sorted.vcf.gz",
            caller=config.get("bcbio_variation_recall_ensemble", {}).get("callers", []),
        ),
        ref=config["reference"]["fasta"],
    output:
        vcf=temp("snv_indels/bcbio_variation_recall_ensemble/{sample}_{type}.ensembled.vcf.gz"),
        bcbio_work=temp(directory("snv_indels/bcbio_variation_recall_ensemble/{sample}_{type}.ensembled-work/")),
    log:
        "snv_indels/bcbio_variation_recall_ensemble/{sample}_{type}.ensembled.vcf.gz.log",
    benchmark:
        repeat(
            "snv_indels/bcbio_variation_recall_ensemble/{sample}_{type}.ensembled.vcf.gz.benchmark.tsv",
            config.get("bcbio_variation_recall_ensemble", {}).get("benchmark_repeats", 1),
        )


use rule bcftools_concat from snv_indels as snv_indels_concat_vcfs with:
    input:
        calls=[
            "snv_indels/bcbio_variation_recall_ensemble/{sample}_{type}.ensembled.vep_annotated.artifact_annotated.background_annotated.filter.somatic.vcf.gz",
            "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.sorted.vep_annotated.artifact_annotated.vcf.gz",
        ],
        index=[
            "snv_indels/bcbio_variation_recall_ensemble/{sample}_{type}.ensembled.vep_annotated.artifact_annotated.background_annotated.filter.somatic.vcf.gz.tbi",
            "cnv_sv/pindel_vcf/{sample}_{type}.no_tc.normalized.merged_af.sorted.vep_annotated.artifact_annotated.vcf.gz.tbi",
        ],
    output:
        vcf=temp("snv_indels/bcftools_concat/{sample}_{type}.filter.somatic.vcf.gz"),
    params:
        extra=config.get("bcftools_concat_vcfs", {}).get("extra", ""),
    log:
        "snv_indels/bcftools_concat/{sample}_{type}.filter.somatic.vcf.gz.log",
    benchmark:
        repeat(
            "snv_indels/bcftools_concat/{sample}_{type}.filter.somatic.vcf.gz.benchmark.tsv",
            config.get("bcftools_concat", {}).get("benchmark_repeats", 1),
        )


module qc:
    snakefile:
        get_module_snakefile(
            config,
            "hydra-genetics/qc",
            path="workflow/Snakefile",
            tag=config["modules"]["snv_indels"],
        )
    config:
        config


# use rule mosdepth_bed from qc as qc_mosdepth_bed with:
#     output:
#         bed=temp("qc/mosdepth_bed/{sample}_{type}.regions.bed.gz"),
#         bed_csi=temp("qc/mosdepth_bed/{sample}_{type}.regions.bed.gz.csi"),
#         coverage=temp("qc/mosdepth_bed/{sample}_{type}.per-base.bed.gz"),
#         coverage_csi=temp("qc/mosdepth_bed/{sample}_{type}.per-base.bed.gz.csi"),
#         thresholds=temp("qc/mosdepth_bed/{sample}_{type}.thresholds.bed.gz"),
#         glob=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.global.dist.txt"),
#         region=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.region.dist.txt"),
#         summary=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.summary.txt"),
#     params:
#         thresholds=config["mosdepth_bed"]["thresholds"],


use rule mosdepth_bed from qc as qc_mosdepth_bed_coding with:
    input:
        bam="alignment/samtools_merge_bam/{sample}_{type}.bam",
        bai="alignment/samtools_merge_bam/{sample}_{type}.bam.bai",
        bed=config.get("reference", {}).get("exon_bed", ""),
    output:
        bed=temp("qc/mosdepth_bed_coding/{sample}_{type}.regions.bed.gz"),
        bed_csi=temp("qc/mosdepth_bed_coding/{sample}_{type}.regions.bed.gz.csi"),
        coverage=temp("qc/mosdepth_bed_coding/{sample}_{type}.per-base.bed.gz"),
        coverage_csi=temp("qc/mosdepth_bed_coding/{sample}_{type}.per-base.bed.gz.csi"),
        thresholds=temp("qc/mosdepth_bed_coding/{sample}_{type}.thresholds.bed.gz"),
        glob=temp("qc/mosdepth_bed_coding/{sample}_{type}.mosdepth.global.dist.txt"),
        region=temp("qc/mosdepth_bed_coding/{sample}_{type}.mosdepth.region.dist.txt"),
        summary=temp("qc/mosdepth_bed_coding/{sample}_{type}.mosdepth.summary.txt"),
    params:
        thresholds=config["mosdepth_bed"]["thresholds"],
    log:
        "qc/mosdepth_bed_coding/{sample}_{type}.mosdepth.summary.txt.log",
    benchmark:
        repeat(
            "qc/mosdepth_bed_coding/{sample}_{type}.mosdepth.summary.txt.benchmark.tsv",
            config.get("mosdepth_bed", {}).get("benchmark_repeats", 1),
        )


use rule multiqc from qc as qc_multiqc with:
    input:
        files=lambda wildcards: set(
            [
                file.format(sample=sample, type=u.type, lane=u.lane, flowcell=u.flowcell, barcode=u.barcode, read=read, ext=ext)
                for file in config["multiqc"]["reports"][wildcards.report]["qc_files"]
                for sample in get_samples(samples)
                for u in units.loc[sample].dropna().itertuples()
                if u.type in config["multiqc"]["reports"][wildcards.report]["included_unit_types"]
                for read in ["fastq1", "fastq2"]
                for ext in config.get("picard_collect_multiple_metrics", {}).get("output_ext", [""])
            ]
        ),
        config=lambda wildcards: config["multiqc"]["reports"][wildcards.report]["config"],
        sample_order="qc/multiqc/sample_order.tsv",
        sample_replacement="qc/multiqc/sample_replacement.tsv",
    params:
        extra=lambda wildcards, input: "--replace-names "
        + input.sample_replacement
        + " --sample-names "
        + input.sample_order
        + " -c "
        + input.config,
